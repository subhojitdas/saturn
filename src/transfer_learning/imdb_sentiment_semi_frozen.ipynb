{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-18T13:43:49.784940Z",
     "start_time": "2025-05-18T13:43:49.500140Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from datasets import load_dataset"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:43:39.734859Z",
     "start_time": "2025-05-18T13:43:37.421242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, sys\n",
    "project_root = os.path.abspath('/Users/subhojit/workspace/saturn/src')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from transfer_learning.bert_plus import *"
   ],
   "id": "cf2a6de3e4a58042",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/subhojit/workspace/saturn/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/subhojit/workspace/saturn/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:44:03.245789Z",
     "start_time": "2025-05-18T13:43:52.440338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = load_dataset('imdb')\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']\n"
   ],
   "id": "6bc24886135b6d1e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:44:05.324260Z",
     "start_time": "2025-05-18T13:44:04.960698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenize = lambda x: tokenizer(x[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "import torch.nn as nn\n"
   ],
   "id": "423e48b9c84d03f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:44:06.917688Z",
     "start_time": "2025-05-18T13:44:06.632400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_tokenized = train_dataset.map(tokenize, batched=True)\n",
    "test_tokenized = test_dataset.map(tokenize, batched=True)"
   ],
   "id": "c0b1f7c4e7f6b847",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:44:07.687542Z",
     "start_time": "2025-05-18T13:44:07.684710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
   ],
   "id": "b87828f68119557f",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:44:08.767262Z",
     "start_time": "2025-05-18T13:44:08.762093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_tokenized, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_tokenized, batch_size=batch_size)\n"
   ],
   "id": "cd7e883907afe684",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:44:10.071850Z",
     "start_time": "2025-05-18T13:44:10.064458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for batch in train_loader:\n",
    "    print(batch.keys())\n",
    "    break"
   ],
   "id": "4811f402e7b3828b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['label', 'input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:46:04.428335Z",
     "start_time": "2025-05-18T13:46:04.410531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_dim = 32\n",
    "hidden_size = 64\n",
    "output_size = 2\n",
    "seq_len = 10\n",
    "learning_rate = 1e-3\n",
    "max_iter = 5000\n",
    "eval_interval = 500\n",
    "\n",
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ],
   "id": "fa1cc101493efe18",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:50:54.289519Z",
     "start_time": "2025-05-18T13:46:33.257938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1-batch overfit\n",
    "batch = next(iter(train_loader))\n",
    "model = SemiFrozenBERTClassifier().to(device)\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': model.classifier.parameters(), 'lr': 2e-4},\n",
    "    {'params': model.bert.encoder.layer[11].parameters(), 'lr': 1e-5},\n",
    "    {'params': model.bert.encoder.layer[10].parameters(), 'lr': 1e-5},\n",
    "])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for step in range(100):\n",
    "    model.train()\n",
    "    logits = model(batch['input_ids'].to(device), batch['attention_mask'].to(device))\n",
    "    labels = batch['label'].to(device)\n",
    "    loss = criterion(logits, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(loss.item())\n"
   ],
   "id": "8be695d7722014e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6787136793136597\n",
      "0.6700606346130371\n",
      "0.6636359095573425\n",
      "0.6454020738601685\n",
      "0.6270042061805725\n",
      "0.6250820755958557\n",
      "0.6177058219909668\n",
      "0.5975170135498047\n",
      "0.5820800065994263\n",
      "0.5659152269363403\n",
      "0.550234854221344\n",
      "0.526050865650177\n",
      "0.5141038298606873\n",
      "0.4885838031768799\n",
      "0.4771472215652466\n",
      "0.4631776213645935\n",
      "0.4466305375099182\n",
      "0.4283401370048523\n",
      "0.40658828616142273\n",
      "0.37958675622940063\n",
      "0.35350340604782104\n",
      "0.3469786047935486\n",
      "0.32961970567703247\n",
      "0.3212670087814331\n",
      "0.28489410877227783\n",
      "0.2770461440086365\n",
      "0.2505478858947754\n",
      "0.2250167429447174\n",
      "0.21140539646148682\n",
      "0.20824676752090454\n",
      "0.19729341566562653\n",
      "0.15676163136959076\n",
      "0.15898293256759644\n",
      "0.18108299374580383\n",
      "0.11832742393016815\n",
      "0.12122823297977448\n",
      "0.10366817563772202\n",
      "0.07910440117120743\n",
      "0.10409163683652878\n",
      "0.061882488429546356\n",
      "0.058903373777866364\n",
      "0.07141883671283722\n",
      "0.05030558258295059\n",
      "0.05123717337846756\n",
      "0.035245999693870544\n",
      "0.029277050867676735\n",
      "0.034901637583971024\n",
      "0.026213137432932854\n",
      "0.04502221569418907\n",
      "0.022775467485189438\n",
      "0.020667986944317818\n",
      "0.013237758539617062\n",
      "0.009664809331297874\n",
      "0.011598693206906319\n",
      "0.01135280355811119\n",
      "0.01097937859594822\n",
      "0.0072595542296767235\n",
      "0.0108083700761199\n",
      "0.016069475561380386\n",
      "0.007194026838988066\n",
      "0.004833046346902847\n",
      "0.006511774845421314\n",
      "0.012343085370957851\n",
      "0.008815117180347443\n",
      "0.005598291289061308\n",
      "0.004154345951974392\n",
      "0.009294403716921806\n",
      "0.0032719741575419903\n",
      "0.006956182420253754\n",
      "0.004378253594040871\n",
      "0.003003946505486965\n",
      "0.004078788682818413\n",
      "0.004104831721633673\n",
      "0.0034587536938488483\n",
      "0.003166095819324255\n",
      "0.002341944258660078\n",
      "0.004636851139366627\n",
      "0.0024538524448871613\n",
      "0.0019961949437856674\n",
      "0.0031877635046839714\n",
      "0.001483601750805974\n",
      "0.0033126268535852432\n",
      "0.0036950171925127506\n",
      "0.001739885308779776\n",
      "0.0025606181006878614\n",
      "0.0016807450447231531\n",
      "0.0030753647442907095\n",
      "0.003831289242953062\n",
      "0.005822116509079933\n",
      "0.0016660626279190183\n",
      "0.0011356978211551905\n",
      "0.0007239420665428042\n",
      "0.001284292433410883\n",
      "0.0013750880025327206\n",
      "0.0035110581666231155\n",
      "0.001348290010355413\n",
      "0.0009503039764240384\n",
      "0.007663557305932045\n",
      "0.001074323896318674\n",
      "0.0009678944479674101\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:20:10.115456Z",
     "start_time": "2025-05-18T13:06:20.562678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = FrozenBERTClassifier().to(device)\n",
    "optimizer = torch.optim.AdamW(model.classifier.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(3):\n",
    "    step = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Epoch: {epoch}, Step {step} Loss: {loss.item():.4f}\")\n",
    "        step += 1"
   ],
   "id": "22b4b2904f4de0bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 Loss: 0.6896\n",
      "Step 100 Loss: 0.3358\n",
      "Step 200 Loss: 0.2901\n",
      "Step 300 Loss: 0.3526\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:35:30.733993Z",
     "start_time": "2025-05-18T13:33:04.259302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_accuracy(model, dataloader):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        all_predictions.extend(predictions.cpu().tolist())\n",
    "        all_labels.extend(labels.cpu().tolist())\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    return accuracy\n",
    "\n",
    "compute_accuracy(model, test_loader)"
   ],
   "id": "b205b968e33a4729",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 20\u001B[0m\n\u001B[1;32m     17\u001B[0m     accuracy \u001B[38;5;241m=\u001B[39m accuracy_score(all_labels, all_predictions)\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m accuracy\n\u001B[0;32m---> 20\u001B[0m \u001B[43mcompute_accuracy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/saturn/.venv/lib/python3.9/site-packages/torch/utils/_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[17], line 10\u001B[0m, in \u001B[0;36mcompute_accuracy\u001B[0;34m(model, dataloader)\u001B[0m\n\u001B[1;32m      7\u001B[0m all_labels \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m dataloader:\n\u001B[0;32m---> 10\u001B[0m     input_ids \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     11\u001B[0m     attention_mask \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     12\u001B[0m     labels \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n",
      "Cell \u001B[0;32mIn[17], line 10\u001B[0m, in \u001B[0;36mcompute_accuracy\u001B[0;34m(model, dataloader)\u001B[0m\n\u001B[1;32m      7\u001B[0m all_labels \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m dataloader:\n\u001B[0;32m---> 10\u001B[0m     input_ids \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     11\u001B[0m     attention_mask \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     12\u001B[0m     labels \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:1103\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:1061\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py:169\u001B[0m, in \u001B[0;36mstop\u001B[0;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[1;32m    167\u001B[0m     frame \u001B[38;5;241m=\u001B[39m suspend_jupyter(main_debugger, thread, frame, step_cmd)\n\u001B[1;32m    168\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m frame:\n\u001B[0;32m--> 169\u001B[0m         \u001B[43mmain_debugger\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    170\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1220\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1217\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1219\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1220\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1229\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1225\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m info\u001B[38;5;241m.\u001B[39mpydev_state \u001B[38;5;241m==\u001B[39m STATE_SUSPEND \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_finish_debugging_session:\n\u001B[1;32m   1226\u001B[0m     \u001B[38;5;66;03m# before every stop check if matplotlib modules were imported inside script code\u001B[39;00m\n\u001B[1;32m   1227\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_activate_mpl_if_needed()\n\u001B[0;32m-> 1229\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[43minfo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpydev_state\u001B[49m \u001B[38;5;241m==\u001B[39m STATE_SUSPEND \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_finish_debugging_session:\n\u001B[1;32m   1230\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmpl_in_use:\n\u001B[1;32m   1231\u001B[0m             \u001B[38;5;66;03m# call input hooks if only matplotlib is in use\u001B[39;00m\n\u001B[1;32m   1232\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "32666a804586c565"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
