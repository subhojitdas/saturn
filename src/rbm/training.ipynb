{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os, sys\n",
    "project_root = os.path.abspath('/Users/subhojit/workspace/saturn/src')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from rbm.rbm import RBM\n",
    "from rbm.auto_encoder import DeepAutoEncoder\n",
    "from rbm.auto_encoder_random_init_weight import DeepAutoEncoderWithRandomInitWeight"
   ],
   "id": "f58b3b54a84e5e47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: torch.bernoulli(x)),\n",
    "])"
   ],
   "id": "8872a2ace6584622",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "mnist = torchvision.datasets.MNIST(root='./dataset', train=True, download=True, transform=transforms)",
   "id": "45e2a3865d349e10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loader = DataLoader(mnist, batch_size=64, shuffle=True)\n",
    "learning_rate = 0.1\n",
    "n_visible = 784\n",
    "n_hidden = 256\n",
    "epochs = 5"
   ],
   "id": "536d524fc7f41f7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# rbm = RBM(n_visible=n_visible, n_hidden=n_hidden)\n",
    "# optimizer = torch.optim.AdamW(rbm.parameters(), lr=learning_rate)\n",
    "#\n",
    "# for epoch in range(epochs):\n",
    "#     total_loss = 0.0\n",
    "#\n",
    "#     for batch, _ in loader:\n",
    "#         v = batch.view(-1, n_visible)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss = rbm.cd_step(v)\n",
    "#         optimizer.step()\n",
    "#         total_loss += loss\n",
    "#\n",
    "#     print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f}\")"
   ],
   "id": "c9b4ee1ffda0dd19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T13:11:05.632803Z",
     "start_time": "2025-06-01T13:11:05.628193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pretrain RBM\n",
    "def pretrain_rbm(rbm, data_loader, epoch=5, lr=0.1):\n",
    "    optimizer = torch.optim.AdamW(rbm.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for batch, _ in data_loader:\n",
    "            v = batch.view(-1, rbm.W.shape[0])\n",
    "            optimizer.zero_grad()\n",
    "            loss = rbm.cd_step(v)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"RBM {rbm.W.shape[0]}->{rbm.W.shape[1]} Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "\n",
    "def transform_data(data_loader, rbm_stack):\n",
    "    result = []\n",
    "    for batch, _ in data_loader:\n",
    "        with torch.no_grad():\n",
    "            for rbm in rbm_stack:\n",
    "                v = batch.view(-1, rbm.W.shape[0])\n",
    "                x = rbm(v)\n",
    "        result.append(x)\n",
    "    return torch.cat(result, dim=0)"
   ],
   "id": "f8778dfa2238a31c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(mnist, batch_size=64, shuffle=True)\n",
    "\n",
    "rbm1 = RBM(784, 500)\n",
    "pretrain_rbm(rbm1, train_loader)\n",
    "h1 = transform_data(train_loader, [rbm1])\n",
    "loader_h1 = DataLoader([(x, 0) for x in h1], batch_size=64, shuffle=True)\n",
    "\n",
    "rbm2 = RBM(500, 250)\n",
    "pretrain_rbm(rbm2, loader_h1)\n",
    "h2 = transform_data(loader_h1, [rbm2])\n",
    "loader_h2 = DataLoader([(x, 0) for x in h2], batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "rbm3 = RBM(250, 125)\n",
    "pretrain_rbm(rbm3, loader_h2)\n",
    "h3 = transform_data(loader_h2, [rbm3])\n",
    "loader_h3 = DataLoader([(x, 0) for x in h3], batch_size=64, shuffle=True)\n",
    "\n",
    "rbm4 = RBM(125, 2)\n",
    "pretrain_rbm(rbm2, loader_h3)"
   ],
   "id": "2c73227767893c02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = DeepAutoEncoder(rbm1, rbm2, rbm3, rbm4)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    for batch, _ in loader:\n",
    "        x = batch.view(-1, n_visible)\n",
    "        optimizer.zero_grad()\n",
    "        recon = model(x)\n",
    "        loss = loss_fn(recon, x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Fine-tuning Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n"
   ],
   "id": "5f6fc0b49ecc61bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T13:12:07.154719Z",
     "start_time": "2025-06-01T13:11:51.391895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Auto encoder training with backprop without any pretraining\n",
    "model = DeepAutoEncoderWithRandomInitWeight()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    for batch, _ in loader:\n",
    "        x = batch.view(-1, n_visible)\n",
    "        optimizer.zero_grad()\n",
    "        recon = model(x)\n",
    "        loss = loss_fn(recon, x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Fine-tuning Epoch {epoch + 1}, Loss: {total_loss:.4f}\")\n",
    "\n"
   ],
   "id": "67390a4016701f34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 1, Loss: 3114.6280\n",
      "Fine-tuning Epoch 2, Loss: 6003.9148\n",
      "Fine-tuning Epoch 3, Loss: 5791.3560\n",
      "Fine-tuning Epoch 4, Loss: 4815.9262\n",
      "Fine-tuning Epoch 5, Loss: 3115.8646\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b7a2de702d6738e9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
