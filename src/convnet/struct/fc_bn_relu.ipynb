{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-25T22:23:01.044813Z",
     "start_time": "2025-04-25T22:23:01.039652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "from convnet.struct.loss import SoftmaxCrossEntropyLoss\n",
    "\n",
    "project_root = os.path.abspath('/Users/subhojit/workspace/saturn/src')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "import convnet.struct\n",
    "from convnet.data_loader import CIFAR_10_DataLoader\n",
    "from convnet.struct.layers import Linear, ReLU, Model, BatchNorm1d\n",
    "\n",
    "importlib.reload(convnet.struct.layers)\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T22:29:01.395853Z",
     "start_time": "2025-04-25T22:29:01.391055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def random_crop_and_flip(flat_image, crop_size=32, padding=4):\n",
    "    image = flat_image.reshape(3, 32, 32)\n",
    "\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "\n",
    "    padded_image = np.pad(image, ((padding, padding), (padding, padding), (0, 0)), mode='constant')\n",
    "\n",
    "    top = np.random.randint(0, 2 * padding)\n",
    "    left = np.random.randint(0, 2 * padding)\n",
    "    cropped = padded_image[top:top+crop_size, left:left+crop_size, :]\n",
    "\n",
    "    if np.random.rand() < 0.5:\n",
    "        cropped = np.fliplr(cropped)\n",
    "\n",
    "    cropped = np.transpose(cropped, (2, 0, 1))\n",
    "\n",
    "    return cropped.reshape(-1)"
   ],
   "id": "b42f94b1110366ae",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T22:29:03.641490Z",
     "start_time": "2025-04-25T22:29:03.358831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_directory = '/Users/subhojit/Downloads/cifar-10-batches-py'\n",
    "cdl = CIFAR_10_DataLoader()\n",
    "xtrain_data, ytrain_data, Xtest, ytest = cdl.load_cifar_10_dataset(file_directory)\n",
    "\n",
    "xtrain_data = xtrain_data.astype('float32') / 255.0\n",
    "Xtest = Xtest.astype('float32') / 255.0\n",
    "\n",
    "# np.random.shuffle(Xtrain)\n",
    "n1 = int(0.8 * len(xtrain_data))\n",
    "Xtrain = xtrain_data[:n1]\n",
    "ytrain = ytrain_data[:n1]\n",
    "Xdev = xtrain_data[n1:]\n",
    "ydev = ytrain_data[n1:]\n",
    "\n",
    "num_classes = len(set(ytrain))"
   ],
   "id": "ad1b791d6b7cbb42",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T22:29:05.534439Z",
     "start_time": "2025-04-25T22:29:05.524431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# data preparation\n",
    "np.random.seed(231)\n",
    "std_dev = 1e-3\n",
    "n_hidden = 100\n",
    "weight_decay = 1e-4 # regularization\n",
    "\n",
    "layers = [\n",
    "    Linear(3072, n_hidden, have_bias=False, std_dev=std_dev, weight_decay=weight_decay),\n",
    "    BatchNorm1d(n_hidden),\n",
    "    ReLU(),\n",
    "    # Linear(n_hidden, n_hidden, have_bias=False, std_dev=std_dev, weight_decay=weight_decay),\n",
    "    # BatchNorm1d(n_hidden),\n",
    "    # ReLU(),\n",
    "    Linear(n_hidden, n_hidden, have_bias=False, std_dev=std_dev, weight_decay=weight_decay),\n",
    "    BatchNorm1d(n_hidden),\n",
    "    ReLU(),\n",
    "    Linear(n_hidden, num_classes, have_bias=False, std_dev=std_dev, weight_decay=weight_decay)\n",
    "]\n",
    "\n",
    "model = Model(layers)\n",
    "loss_criteria = SoftmaxCrossEntropyLoss()\n",
    "\n",
    "params = [p for layer in layers for p in layer.parameters()]\n",
    "\n",
    "print(sum(par.size for par in params))"
   ],
   "id": "dcc768700d8b39ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318600\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T22:30:09.745798Z",
     "start_time": "2025-04-25T22:29:08.534782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_iterations = 10000\n",
    "batch_size = 128\n",
    "lossi = []\n",
    "Hs = []\n",
    "\n",
    "for i in range(max_iterations):\n",
    "\n",
    "    #mini batch\n",
    "    ix = np.random.randint(0, Xtrain.shape[0], (batch_size,))\n",
    "    Xb, Yb = Xtrain[ix], ytrain[ix]\n",
    "    Xbatch_aug = np.array([random_crop_and_flip(img) for img in Xb])\n",
    "    Xbatch_aug = Xbatch_aug.reshape(Xbatch_aug.shape[0], -1)\n",
    "\n",
    "    #farward pass\n",
    "    x = Xbatch_aug\n",
    "    logits = model.forward(x)\n",
    "    data_loss = loss_criteria.forward(logits, Yb)\n",
    "    reg_loss = loss_criteria.l2_regularization(model, 1e-4)\n",
    "    loss = data_loss + reg_loss\n",
    "    lossi.append(loss)\n",
    "\n",
    "    #backward pass\n",
    "    logit_grad = loss_criteria.backward()\n",
    "    model.backward(logit_grad)\n",
    "\n",
    "    #param update\n",
    "    lr = 0.1\n",
    "    model.update_param(lr)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"loss: {loss:.4f}\")"
   ],
   "id": "56988979219fc7b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.3022\n",
      "loss: 1.9651\n",
      "loss: 1.8486\n",
      "loss: 1.8516\n",
      "loss: 1.6233\n",
      "loss: 1.5990\n",
      "loss: 1.5339\n",
      "loss: 1.4189\n",
      "loss: 1.5226\n",
      "loss: 1.5736\n",
      "loss: 1.3911\n",
      "loss: 1.4848\n",
      "loss: 1.4304\n",
      "loss: 1.6856\n",
      "loss: 1.4702\n",
      "loss: 1.4208\n",
      "loss: 1.5312\n",
      "loss: 1.6363\n",
      "loss: 1.4840\n",
      "loss: 1.3871\n",
      "loss: 1.5261\n",
      "loss: 1.5978\n",
      "loss: 1.5132\n",
      "loss: 1.4527\n",
      "loss: 1.5880\n",
      "loss: 1.3296\n",
      "loss: 1.5343\n",
      "loss: 1.3188\n",
      "loss: 1.4898\n",
      "loss: 1.3793\n",
      "loss: 1.3686\n",
      "loss: 1.5023\n",
      "loss: 1.2423\n",
      "loss: 1.4257\n",
      "loss: 1.5395\n",
      "loss: 1.3478\n",
      "loss: 1.3906\n",
      "loss: 1.3387\n",
      "loss: 1.5277\n",
      "loss: 1.4182\n",
      "loss: 1.2422\n",
      "loss: 1.4611\n",
      "loss: 1.3370\n",
      "loss: 1.4391\n",
      "loss: 1.3964\n",
      "loss: 1.2113\n",
      "loss: 1.3632\n",
      "loss: 1.3386\n",
      "loss: 1.3101\n",
      "loss: 1.2646\n",
      "loss: 1.4768\n",
      "loss: 1.3548\n",
      "loss: 1.3525\n",
      "loss: 1.4008\n",
      "loss: 1.4479\n",
      "loss: 1.3497\n",
      "loss: 1.2786\n",
      "loss: 1.4238\n",
      "loss: 1.4043\n",
      "loss: 1.4349\n",
      "loss: 1.2908\n",
      "loss: 1.1472\n",
      "loss: 1.2260\n",
      "loss: 1.2990\n",
      "loss: 1.4005\n",
      "loss: 1.3257\n",
      "loss: 1.2363\n",
      "loss: 1.2476\n",
      "loss: 1.3522\n",
      "loss: 1.1855\n",
      "loss: 1.4287\n",
      "loss: 1.4927\n",
      "loss: 1.3730\n",
      "loss: 1.2734\n",
      "loss: 1.3179\n",
      "loss: 1.3133\n",
      "loss: 1.2343\n",
      "loss: 1.3782\n",
      "loss: 1.3880\n",
      "loss: 1.3462\n",
      "loss: 1.1738\n",
      "loss: 1.3035\n",
      "loss: 1.2210\n",
      "loss: 1.1510\n",
      "loss: 1.2300\n",
      "loss: 1.3220\n",
      "loss: 1.3947\n",
      "loss: 1.4108\n",
      "loss: 1.3114\n",
      "loss: 1.4636\n",
      "loss: 1.2068\n",
      "loss: 1.3455\n",
      "loss: 1.1569\n",
      "loss: 1.3818\n",
      "loss: 1.3341\n",
      "loss: 1.3081\n",
      "loss: 1.2369\n",
      "loss: 1.4402\n",
      "loss: 1.2092\n",
      "loss: 1.2501\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T22:28:08.881506Z",
     "start_time": "2025-04-25T22:28:08.877959Z"
    }
   },
   "cell_type": "code",
   "source": "Xb[0].shape",
   "id": "de5bf61018cbae8c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T22:30:24.887090Z",
     "start_time": "2025-04-25T22:30:24.596240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_loss(split):\n",
    "    x, y = {\n",
    "        'train': (Xtrain, ytrain),\n",
    "        'dev': (Xdev, ydev),\n",
    "        'test': (Xtest, ytest),\n",
    "    }[split]\n",
    "    for layer in layers:\n",
    "        if isinstance(layer, BatchNorm1d):\n",
    "            layer.train = False\n",
    "        x = layer.forward(x)\n",
    "    logits = x\n",
    "    loss = loss_criteria.forward(logits, y)\n",
    "    print(f\"{split} => loss: {loss:.4f}\")\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('dev')"
   ],
   "id": "5e0672e008bb7832",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train => loss: 1.2107\n",
      "dev => loss: 1.2835\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T22:30:29.378822Z",
     "start_time": "2025-04-25T22:30:29.307661Z"
    }
   },
   "cell_type": "code",
   "source": "split_loss('test')",
   "id": "ca88e01afc67265b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test => loss: 1.2823\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T22:30:31.593909Z",
     "start_time": "2025-04-25T22:30:31.524070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def accuracy(x, labels):\n",
    "    for layer in layers:\n",
    "        if isinstance(layer, BatchNorm1d):\n",
    "            layer.train = False\n",
    "        x = layer.forward(x)\n",
    "    logits = x\n",
    "    probs = loss_criteria.softmax_numpy(logits)\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    return np.mean(preds == labels)\n",
    "\n",
    "accuracy(Xtest, ytest)"
   ],
   "id": "6333197fc61e5f5e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5448)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Note\n",
    "Here at the beginning I have lots of layers which was overfitting the training data. That is it is memorizing the training data and not generaizing properly. That reflects in the training loss and dev loss being far apart. I got a training loss of 0.6 and dev loss of 2.2 and test loss at similar scale with dev loss and getting accuracy of ~51% on testset.\n",
    "Then introducing l2 regularization does not fix the problem completely. When I added horizontal flipping, cropping the images , the overfitting stopped and train and dev loss came to similar scale.\n",
    "\n"
   ],
   "id": "9748c17d45b90c4d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
