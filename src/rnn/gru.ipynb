{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "# ---- Setup ----\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Vocabulary: a-z + special tokens\n",
    "all_characters = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "special_tokens = ['<SOS>', '<EOS>']\n",
    "all_tokens = special_tokens + list(all_characters)\n",
    "n_characters = len(all_tokens)\n",
    "\n",
    "char_to_idx = {ch: idx for idx, ch in enumerate(all_tokens)}\n",
    "idx_to_char = {idx: ch for ch, idx in char_to_idx.items()}\n",
    "\n",
    "SOS_idx = char_to_idx['<SOS>']\n",
    "EOS_idx = char_to_idx['<EOS>']\n",
    "\n",
    "# Helpers\n",
    "def string_to_tensor(name):\n",
    "    indices = [char_to_idx[c] for c in name]\n",
    "    return torch.tensor(indices, dtype=torch.long)\n",
    "\n",
    "def tensor_to_string(tensor):\n",
    "    chars = [idx_to_char[idx.item()] for idx in tensor]\n",
    "    return ''.join(chars)\n",
    "\n",
    "# ---- Model ----\n",
    "\n",
    "class NameRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
    "        super(NameRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRUCell(embedding_dim, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_idx, hidden):\n",
    "        embedded = self.embedding(input_idx)\n",
    "        hidden = self.gru(embedded, hidden)\n",
    "        output = self.fc(hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size=1):\n",
    "        return torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "\n",
    "# ---- Instantiate ----\n",
    "\n",
    "embedding_dim = 128\n",
    "hidden_size = 512\n",
    "rnn = NameRNN(n_characters, embedding_dim, hidden_size).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.003)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3000, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ---- Data Preparation ----\n",
    "\n",
    "# Your real dataset (replace this with your full 6000 names list)\n",
    "training_data = [\"arjun\", \"anita\", \"bharat\", \"devika\", \"rajat\", \"suman\", \"priya\"]\n",
    "\n",
    "def prepare_batch(names, batch_size):\n",
    "    batch_inputs = []\n",
    "    batch_targets = []\n",
    "\n",
    "    for _ in range(batch_size):\n",
    "        name = random.choice(names)\n",
    "        name = ['<SOS>'] + list(name) + ['<EOS>']\n",
    "\n",
    "        input_seq = [char_to_idx[ch] for ch in name[:-1]]\n",
    "        target_seq = [char_to_idx[ch] for ch in name[1:]]\n",
    "\n",
    "        batch_inputs.append(torch.tensor(input_seq, dtype=torch.long))\n",
    "        batch_targets.append(torch.tensor(target_seq, dtype=torch.long))\n",
    "\n",
    "    # Pad sequences to same length\n",
    "    input_lengths = [len(seq) for seq in batch_inputs]\n",
    "    max_len = max(input_lengths)\n",
    "\n",
    "    padded_inputs = torch.zeros(batch_size, max_len, dtype=torch.long)\n",
    "    padded_targets = torch.zeros(batch_size, max_len, dtype=torch.long)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        padded_inputs[i, :input_lengths[i]] = batch_inputs[i]\n",
    "        padded_targets[i, :input_lengths[i]] = batch_targets[i]\n",
    "\n",
    "    return padded_inputs.to(device), padded_targets.to(device), input_lengths\n",
    "\n",
    "# ---- Training ----\n",
    "\n",
    "def train_step(batch_inputs, batch_targets, input_lengths):\n",
    "    rnn.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    batch_size, seq_len = batch_inputs.shape\n",
    "    hidden = rnn.init_hidden(batch_size)\n",
    "\n",
    "    loss = 0\n",
    "    for t in range(seq_len):\n",
    "        input_t = batch_inputs[:, t]\n",
    "        target_t = batch_targets[:, t]\n",
    "\n",
    "        output, hidden = rnn(input_t, hidden)\n",
    "        loss += criterion(output, target_t)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    return loss.item() / seq_len\n",
    "\n",
    "# ---- Sampling ----\n",
    "\n",
    "def sample(start_letter='<SOS>', temperature=0.8, max_length=20):\n",
    "    rnn.eval()\n",
    "    with torch.no_grad():\n",
    "        if start_letter == '<SOS>':\n",
    "            input_idx = torch.tensor([SOS_idx], device=device)\n",
    "        else:\n",
    "            input_idx = torch.tensor([char_to_idx[start_letter]], device=device)\n",
    "\n",
    "        hidden = rnn.init_hidden(1)\n",
    "\n",
    "        output_name = ''\n",
    "        for _ in range(max_length):\n",
    "            output, hidden = rnn(input_idx, hidden)\n",
    "\n",
    "            output = output.view(-1) / temperature\n",
    "            probs = F.softmax(output, dim=0)\n",
    "            top_idx = torch.multinomial(probs, 1)[0]\n",
    "\n",
    "            predicted_char = idx_to_char[top_idx.item()]\n",
    "\n",
    "            if predicted_char == '<EOS>':\n",
    "                break\n",
    "\n",
    "            output_name += predicted_char\n",
    "            input_idx = top_idx.unsqueeze(0)\n",
    "\n",
    "        return output_name\n",
    "\n",
    "# ---- Main Training Loop ----\n",
    "\n",
    "n_epochs = 20000\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    batch_inputs, batch_targets, input_lengths = prepare_batch(training_data, batch_size)\n",
    "    loss = train_step(batch_inputs, batch_targets, input_lengths)\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "        for _ in range(3):\n",
    "            print(f\"Generated (0.8): {sample(temperature=0.8)}\")\n",
    "            print(f\"Generated (1.2): {sample(temperature=1.2)}\")\n",
    "        print()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T13:52:30.038984Z",
     "start_time": "2025-04-28T13:52:30.025845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for _ in range(30):\n",
    "    print(sample(temperature=2))"
   ],
   "id": "902e641bca303461",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anita\n",
      "devika\n",
      "devika\n",
      "arjun\n",
      "rajat\n",
      "devika\n",
      "priya\n",
      "suman\n",
      "devika\n",
      "priya\n",
      "priya\n",
      "devika\n",
      "anita\n",
      "priya\n",
      "devika\n",
      "arjun\n",
      "bharat\n",
      "arjun\n",
      "suman\n",
      "suman\n",
      "bharat\n",
      "anita\n",
      "suman\n",
      "devanita\n",
      "suman\n",
      "bharat\n",
      "arjun\n",
      "arjun\n",
      "priya\n",
      "devika\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e2f46558e897b382"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
