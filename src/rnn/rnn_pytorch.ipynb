{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T13:34:18.809094Z",
     "start_time": "2025-04-28T13:34:09.416075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "# Let's assume you have these\n",
    "all_characters = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "# Map from char to index and vice-versa\n",
    "char_to_idx = {ch: idx for idx, ch in enumerate(all_characters)}\n",
    "idx_to_char = {idx: ch for idx, ch in enumerate(all_characters)}\n",
    "\n",
    "# Helper to encode a string to tensor of indices\n",
    "def string_to_tensor(string):\n",
    "    tensor = torch.zeros(len(string), dtype=torch.long)\n",
    "    for i, ch in enumerate(string):\n",
    "        tensor[i] = char_to_idx[ch]\n",
    "    return tensor\n",
    "\n",
    "# Helper to decode tensor to string\n",
    "def tensor_to_string(tensor):\n",
    "    return ''.join(idx_to_char[idx.item()] for idx in tensor)\n",
    "\n",
    "# Vanilla RNN Model\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_char, hidden):\n",
    "        # input_char: (batch_size=1, input_size)\n",
    "        # hidden: (batch_size=1, hidden_size)\n",
    "        combined = torch.cat((input_char, hidden), 1) # concatenate\n",
    "        hidden = torch.tanh(self.i2h(combined))\n",
    "        output = self.i2o(combined)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "# Instantiate\n",
    "n_hidden = 128\n",
    "rnn = VanillaRNN(n_characters, n_hidden, n_characters)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.005)\n",
    "\n",
    "# Example dataset\n",
    "training_data = open('indian_names.txt', 'r').read().splitlines()\n",
    "#[\"arjun\", \"anita\", \"bharat\", \"devika\", \"rajat\", \"suman\", \"priya\"]\n",
    "\n",
    "# Training loop\n",
    "def train(input_line):\n",
    "    rnn.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    input_tensor = string_to_tensor(input_line[:-1])  # all chars except last\n",
    "    target_tensor = string_to_tensor(input_line[1:])  # predict next char\n",
    "\n",
    "    hidden = rnn.init_hidden()\n",
    "\n",
    "    loss = 0\n",
    "    for i in range(input_tensor.size(0)):\n",
    "        input_onehot = F.one_hot(input_tensor[i], num_classes=n_characters).float().unsqueeze(0)\n",
    "        output, hidden = rnn(input_onehot, hidden)\n",
    "        loss += criterion(output, target_tensor[i].unsqueeze(0))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item() / input_tensor.size(0)\n",
    "\n",
    "# Generate new names\n",
    "def sample(start_letter='a', max_length=10):\n",
    "    rnn.eval()\n",
    "    with torch.no_grad():\n",
    "        input_tensor = string_to_tensor(start_letter)\n",
    "        input_onehot = F.one_hot(input_tensor[0], num_classes=n_characters).float().unsqueeze(0)\n",
    "        hidden = rnn.init_hidden()\n",
    "\n",
    "        output_name = start_letter\n",
    "\n",
    "        for i in range(max_length):\n",
    "            output, hidden = rnn(input_onehot, hidden)\n",
    "            output_dist = F.softmax(output.view(-1), dim=0)\n",
    "            top_i = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "            predicted_char = idx_to_char[top_i.item()]\n",
    "            output_name += predicted_char\n",
    "\n",
    "            input_onehot = F.one_hot(top_i, num_classes=n_characters).float().unsqueeze(0)\n",
    "\n",
    "        return output_name\n",
    "\n",
    "# Training\n",
    "n_epochs = 20000\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    name = random.choice(training_data)\n",
    "    loss = train(name)\n",
    "\n",
    "    if epoch % 200 == 0:\n",
    "        print(f\"Epoch {epoch} Loss: {loss:.4f}\")\n",
    "        print(\"Generated:\", sample(random.choice(all_characters)))\n",
    "        print()\n",
    "\n"
   ],
   "id": "14a6f48e4fea55ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200 Loss: 3.4424\n",
      "Generated: suudhaiauna\n",
      "\n",
      "Epoch 400 Loss: 2.2950\n",
      "Generated: qmanjitranh\n",
      "\n",
      "Epoch 600 Loss: 2.8994\n",
      "Generated: tyaninaranh\n",
      "\n",
      "Epoch 800 Loss: 3.2802\n",
      "Generated: qayolalgush\n",
      "\n",
      "Epoch 1000 Loss: 2.1609\n",
      "Generated: cihalolmire\n",
      "\n",
      "Epoch 1200 Loss: 2.4945\n",
      "Generated: arktrpiruja\n",
      "\n",
      "Epoch 1400 Loss: 2.6385\n",
      "Generated: qpralavarit\n",
      "\n",
      "Epoch 1600 Loss: 2.7282\n",
      "Generated: obhoreallee\n",
      "\n",
      "Epoch 1800 Loss: 2.5610\n",
      "Generated: vnshadyyara\n",
      "\n",
      "Epoch 2000 Loss: 2.1994\n",
      "Generated: furamanaira\n",
      "\n",
      "Epoch 2200 Loss: 2.3946\n",
      "Generated: aramdsanijd\n",
      "\n",
      "Epoch 2400 Loss: 2.3242\n",
      "Generated: zgyanjarich\n",
      "\n",
      "Epoch 2600 Loss: 2.8852\n",
      "Generated: bidnilgaras\n",
      "\n",
      "Epoch 2800 Loss: 1.8381\n",
      "Generated: pantundttdu\n",
      "\n",
      "Epoch 3000 Loss: 2.1101\n",
      "Generated: lvijhanadin\n",
      "\n",
      "Epoch 3200 Loss: 2.4436\n",
      "Generated: zunatychrbi\n",
      "\n",
      "Epoch 3400 Loss: 2.8381\n",
      "Generated: layannsheri\n",
      "\n",
      "Epoch 3600 Loss: 2.6136\n",
      "Generated: naashalesup\n",
      "\n",
      "Epoch 3800 Loss: 1.7908\n",
      "Generated: jidindunwer\n",
      "\n",
      "Epoch 4000 Loss: 3.2840\n",
      "Generated: gohajakiwat\n",
      "\n",
      "Epoch 4200 Loss: 2.2251\n",
      "Generated: punindatufn\n",
      "\n",
      "Epoch 4400 Loss: 2.0276\n",
      "Generated: ajeegpadhir\n",
      "\n",
      "Epoch 4600 Loss: 2.3071\n",
      "Generated: waralaratil\n",
      "\n",
      "Epoch 4800 Loss: 2.1004\n",
      "Generated: lukasiyankt\n",
      "\n",
      "Epoch 5000 Loss: 2.3036\n",
      "Generated: vavpalarohi\n",
      "\n",
      "Epoch 5200 Loss: 3.3553\n",
      "Generated: shiraraaini\n",
      "\n",
      "Epoch 5400 Loss: 2.3491\n",
      "Generated: sanashandam\n",
      "\n",
      "Epoch 5600 Loss: 1.4832\n",
      "Generated: esikeshagaw\n",
      "\n",
      "Epoch 5800 Loss: 2.8838\n",
      "Generated: dabrdeeeemo\n",
      "\n",
      "Epoch 6000 Loss: 2.4846\n",
      "Generated: kalawaranxm\n",
      "\n",
      "Epoch 6200 Loss: 2.0836\n",
      "Generated: antiddelkee\n",
      "\n",
      "Epoch 6400 Loss: 2.7643\n",
      "Generated: paresuneeoo\n",
      "\n",
      "Epoch 6600 Loss: 1.7981\n",
      "Generated: laxiraqashy\n",
      "\n",
      "Epoch 6800 Loss: 1.5331\n",
      "Generated: eernidenaka\n",
      "\n",
      "Epoch 7000 Loss: 3.1861\n",
      "Generated: orprarirana\n",
      "\n",
      "Epoch 7200 Loss: 2.6816\n",
      "Generated: givrulehaka\n",
      "\n",
      "Epoch 7400 Loss: 2.2839\n",
      "Generated: capolsatand\n",
      "\n",
      "Epoch 7600 Loss: 2.6319\n",
      "Generated: tanjahifaan\n",
      "\n",
      "Epoch 7800 Loss: 1.5447\n",
      "Generated: xaranvinina\n",
      "\n",
      "Epoch 8000 Loss: 1.9103\n",
      "Generated: qurindhaish\n",
      "\n",
      "Epoch 8200 Loss: 2.3508\n",
      "Generated: qijmalleenj\n",
      "\n",
      "Epoch 8400 Loss: 3.6608\n",
      "Generated: ghanannanoo\n",
      "\n",
      "Epoch 8600 Loss: 3.0437\n",
      "Generated: ravtwereela\n",
      "\n",
      "Epoch 8800 Loss: 1.7841\n",
      "Generated: levenizikra\n",
      "\n",
      "Epoch 9000 Loss: 2.1786\n",
      "Generated: qorashuraya\n",
      "\n",
      "Epoch 9200 Loss: 2.4802\n",
      "Generated: wahratabave\n",
      "\n",
      "Epoch 9400 Loss: 2.8623\n",
      "Generated: pamvenuinan\n",
      "\n",
      "Epoch 9600 Loss: 2.5250\n",
      "Generated: iamalchajul\n",
      "\n",
      "Epoch 9800 Loss: 2.7039\n",
      "Generated: vimlyaraand\n",
      "\n",
      "Epoch 10000 Loss: 2.6824\n",
      "Generated: feitimalwem\n",
      "\n",
      "Epoch 10200 Loss: 2.1641\n",
      "Generated: lekhraokara\n",
      "\n",
      "Epoch 10400 Loss: 1.6972\n",
      "Generated: enarinanalb\n",
      "\n",
      "Epoch 10600 Loss: 2.3795\n",
      "Generated: chtipatarab\n",
      "\n",
      "Epoch 10800 Loss: 1.2579\n",
      "Generated: dileramotam\n",
      "\n",
      "Epoch 11000 Loss: 1.8725\n",
      "Generated: morimwasham\n",
      "\n",
      "Epoch 11200 Loss: 2.3515\n",
      "Generated: punakatinkr\n",
      "\n",
      "Epoch 11400 Loss: 1.2319\n",
      "Generated: itwaleeeshe\n",
      "\n",
      "Epoch 11600 Loss: 2.1117\n",
      "Generated: qramenjulil\n",
      "\n",
      "Epoch 11800 Loss: 2.1255\n",
      "Generated: vikritadind\n",
      "\n",
      "Epoch 12000 Loss: 2.6974\n",
      "Generated: zatrajalund\n",
      "\n",
      "Epoch 12200 Loss: 1.9951\n",
      "Generated: yanyankumit\n",
      "\n",
      "Epoch 12400 Loss: 2.3090\n",
      "Generated: haillaminan\n",
      "\n",
      "Epoch 12600 Loss: 2.5131\n",
      "Generated: ergalvellan\n",
      "\n",
      "Epoch 12800 Loss: 2.3489\n",
      "Generated: raminandeth\n",
      "\n",
      "Epoch 13000 Loss: 2.5695\n",
      "Generated: waniraranaf\n",
      "\n",
      "Epoch 13200 Loss: 2.3741\n",
      "Generated: bhazmonitus\n",
      "\n",
      "Epoch 13400 Loss: 2.7901\n",
      "Generated: rizamamamam\n",
      "\n",
      "Epoch 13600 Loss: 2.3224\n",
      "Generated: xidhapndade\n",
      "\n",
      "Epoch 13800 Loss: 1.8172\n",
      "Generated: gelundhuror\n",
      "\n",
      "Epoch 14000 Loss: 3.1021\n",
      "Generated: bhagoodeeee\n",
      "\n",
      "Epoch 14200 Loss: 1.7070\n",
      "Generated: gainilaland\n",
      "\n",
      "Epoch 14400 Loss: 2.5952\n",
      "Generated: kundedikana\n",
      "\n",
      "Epoch 14600 Loss: 1.6278\n",
      "Generated: zafilbbinam\n",
      "\n",
      "Epoch 14800 Loss: 2.3306\n",
      "Generated: lushitumuma\n",
      "\n",
      "Epoch 15000 Loss: 1.9905\n",
      "Generated: nnorekhwave\n",
      "\n",
      "Epoch 15200 Loss: 1.1847\n",
      "Generated: gamstubanun\n",
      "\n",
      "Epoch 15400 Loss: 2.1370\n",
      "Generated: xaanamendde\n",
      "\n",
      "Epoch 15600 Loss: 2.6996\n",
      "Generated: jeenasharam\n",
      "\n",
      "Epoch 15800 Loss: 2.3032\n",
      "Generated: hartilindil\n",
      "\n",
      "Epoch 16000 Loss: 2.3886\n",
      "Generated: ghashalikas\n",
      "\n",
      "Epoch 16200 Loss: 1.7677\n",
      "Generated: uddparirali\n",
      "\n",
      "Epoch 16400 Loss: 1.7800\n",
      "Generated: davatalakil\n",
      "\n",
      "Epoch 16600 Loss: 2.4127\n",
      "Generated: quramadhyar\n",
      "\n",
      "Epoch 16800 Loss: 2.4006\n",
      "Generated: liklangayah\n",
      "\n",
      "Epoch 17000 Loss: 1.2997\n",
      "Generated: osiudeeeetr\n",
      "\n",
      "Epoch 17200 Loss: 1.5593\n",
      "Generated: oremisadddu\n",
      "\n",
      "Epoch 17400 Loss: 2.6738\n",
      "Generated: xamsharyara\n",
      "\n",
      "Epoch 17600 Loss: 2.3043\n",
      "Generated: dainaandhin\n",
      "\n",
      "Epoch 17800 Loss: 2.4115\n",
      "Generated: jamprvileba\n",
      "\n",
      "Epoch 18000 Loss: 2.2276\n",
      "Generated: tahalusulin\n",
      "\n",
      "Epoch 18200 Loss: 1.6671\n",
      "Generated: poochaatana\n",
      "\n",
      "Epoch 18400 Loss: 1.8693\n",
      "Generated: faindhamdee\n",
      "\n",
      "Epoch 18600 Loss: 2.5975\n",
      "Generated: zaikinilire\n",
      "\n",
      "Epoch 18800 Loss: 3.5425\n",
      "Generated: omanurilani\n",
      "\n",
      "Epoch 19000 Loss: 1.6911\n",
      "Generated: uranangoode\n",
      "\n",
      "Epoch 19200 Loss: 2.5444\n",
      "Generated: gvinilarrin\n",
      "\n",
      "Epoch 19400 Loss: 2.7187\n",
      "Generated: etavartinur\n",
      "\n",
      "Epoch 19600 Loss: 2.3017\n",
      "Generated: njanichasha\n",
      "\n",
      "Epoch 19800 Loss: 1.6057\n",
      "Generated: muzmolemash\n",
      "\n",
      "Epoch 20000 Loss: 0.9666\n",
      "Generated: vadhayainaj\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "97afca79bebb0a2d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
