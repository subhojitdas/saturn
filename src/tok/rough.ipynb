{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# code point access\n",
    "ord(\"h\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T14:07:57.026061Z",
     "start_time": "2025-05-17T14:07:57.006865Z"
    }
   },
   "cell_type": "code",
   "source": "import regex as re",
   "id": "e830d7c0483bec77",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ord(\"ğŸ˜€\")",
   "id": "cd53b57fcf8f1267",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ord(\"à¦¹\")",
   "id": "8bc11fe59373026f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ord(\"hello\")",
   "id": "af5b8a8af09d6c73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "s = \"à¦¨à¦®à¦¸à§à¦•à¦¾à¦° (Hello in Bengali)\"\n",
    "c = [ord(x) for x in s]\n",
    "c"
   ],
   "id": "a1b35e433292c09b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "s.encode(\"utf-8\")",
   "id": "aea65024f77b89cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "list(s.encode(\"utf-8\"))",
   "id": "41e19e626a07cdad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test is from https://www.reedbeta.com/blog/programmers-intro-to-unicode/\n",
    "text = \"ï¼µï½ï½‰ï½ƒï½ï½„ï½…! ğŸ…¤ğŸ…ğŸ…˜ğŸ…’ğŸ…ğŸ…“ğŸ…”â€½ ğŸ‡ºâ€ŒğŸ‡³â€ŒğŸ‡®â€ŒğŸ‡¨â€ŒğŸ‡´â€ŒğŸ‡©â€ŒğŸ‡ª! ğŸ˜„ The very name strikes fear and awe into the hearts of programmers worldwide. We all know we ought to â€œsupport Unicodeâ€ in our software (whatever that meansâ€”like using wchar_t for all the strings, right?). But Unicode can be abstruse, and diving into the thousand-page Unicode Standard plus its dozens of supplementary annexes, reports, and notes can be more than a little intimidating. I donâ€™t blame programmers for still finding the whole thing mysterious, even 30 years after Unicodeâ€™s inception.\"\n",
    "tokens = text.encode(\"utf-8\")\n",
    "tokens = list(map(int, tokens))\n",
    "print(text)\n",
    "print(len(text))\n",
    "print(tokens)\n",
    "print(len(tokens))\n"
   ],
   "id": "42bbde9ae9ef2879",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chr(101), chr(32)",
   "id": "16010b20e5d62e28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_stat(ids):\n",
    "    count = {}\n",
    "    for pair in zip(ids, ids[1:]):\n",
    "        count[pair] = count.get(pair, 0) + 1\n",
    "    return count\n",
    "stat = get_stat(tokens)\n",
    "# print(stat)\n",
    "# print(sorted(((v, k) for k, v in stat.items()), reverse=True))"
   ],
   "id": "69492c0300956aac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "top_pair = max(stat, key=stat.get)\n",
    "top_pair"
   ],
   "id": "e0625eb08a38a7d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def merge(ids, pair, idx):\n",
    "    newids = []\n",
    "    i = 0\n",
    "    while i < len(ids):\n",
    "        if i < len(ids) - 1 and ids[i] == pair[0] and ids[i + 1] == pair[1]:\n",
    "            newids.append(idx)\n",
    "            i += 2\n",
    "        else:\n",
    "            newids.append(ids[i])\n",
    "            i += 1\n",
    "    return newids\n",
    "tokens2 = merge(tokens, top_pair, 256)\n",
    "print(tokens2)\n",
    "print(\"Length: \", len(tokens2))"
   ],
   "id": "daf5ab3377dc01af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T13:28:02.222816Z",
     "start_time": "2025-05-17T13:28:02.219549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = open('raw_text.txt', 'r').read()\n",
    "tokens = text.encode(\"utf-8\")\n",
    "tokens = list(map(int, tokens))"
   ],
   "id": "366fec1769260332",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T13:33:48.040337Z",
     "start_time": "2025-05-17T13:33:47.936038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_stat(ids):\n",
    "    count = {}\n",
    "    for pair in zip(ids, ids[1:]):\n",
    "        count[pair] = count.get(pair, 0) + 1\n",
    "    return count\n",
    "stat = get_stat(tokens)\n",
    "\n",
    "def merge(ids, pair, idx):\n",
    "    newids = []\n",
    "    i = 0\n",
    "    while i < len(ids):\n",
    "        if i < len(ids) - 1 and ids[i] == pair[0] and ids[i + 1] == pair[1]:\n",
    "            newids.append(idx)\n",
    "            i += 2\n",
    "        else:\n",
    "            newids.append(ids[i])\n",
    "            i += 1\n",
    "    return newids\n",
    "\n",
    "##--\n",
    "vocab_size = 276\n",
    "num_merges = vocab_size - 256\n",
    "ids = list(tokens)\n",
    "\n",
    "merges = {}\n",
    "for i in range(num_merges):\n",
    "    count = get_stat(ids)\n",
    "    top_pair = max(count, key=count.get)\n",
    "    idx = 256 + i\n",
    "    print(f\"Merging {top_pair} into {idx}\")\n",
    "    ids = merge(ids, top_pair, idx)\n",
    "    merges[top_pair] = idx\n",
    "\n"
   ],
   "id": "d18f96859bb07041",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging (101, 32) into 256\n",
      "Merging (105, 110) into 257\n",
      "Merging (115, 32) into 258\n",
      "Merging (116, 104) into 259\n",
      "Merging (101, 114) into 260\n",
      "Merging (99, 111) into 261\n",
      "Merging (116, 32) into 262\n",
      "Merging (226, 128) into 263\n",
      "Merging (44, 32) into 264\n",
      "Merging (97, 110) into 265\n",
      "Merging (111, 114) into 266\n",
      "Merging (100, 32) into 267\n",
      "Merging (97, 114) into 268\n",
      "Merging (101, 110) into 269\n",
      "Merging (257, 103) into 270\n",
      "Merging (261, 100) into 271\n",
      "Merging (121, 32) into 272\n",
      "Merging (46, 32) into 273\n",
      "Merging (97, 108) into 274\n",
      "Merging (259, 256) into 275\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T13:35:48.170939Z",
     "start_time": "2025-05-17T13:35:48.167507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"tokens length: {len(tokens)}\")\n",
    "print(f\"ids length: {len(ids)}\")\n",
    "print(f\"compression ratio: {len(tokens) / len(ids): .2f}\")"
   ],
   "id": "8aa828a549181b89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens length: 24547\n",
      "ids length: 19384\n",
      "compression ratio:  1.27\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T13:52:19.675368Z",
     "start_time": "2025-05-17T13:52:19.669905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab = {idx: bytes([idx]) for idx in range(256)}\n",
    "for (p0, p1), idx in merges.items():\n",
    "    vocab[idx] = vocab[p0] + vocab[p1]\n",
    "\n",
    "def decode(ids):\n",
    "    # given sequence tokens -> python str\n",
    "    tokens = b\"\".join(vocab[id] for id in ids)\n",
    "    text = tokens.decode(\"utf-8\", errors=\"replace\")\n",
    "    return text\n",
    "\n",
    "decode([128])"
   ],
   "id": "4b2d3ac426b8f352",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ï¿½'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T14:00:14.636544Z",
     "start_time": "2025-05-17T14:00:14.628686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode(text):\n",
    "    # given str -> seq of integers\n",
    "    tokens = text.encode(\"utf-8\")\n",
    "    while len(tokens) >= 2:\n",
    "        stats = get_stat(tokens)\n",
    "        pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
    "        if pair not in merges:\n",
    "            break\n",
    "        idx = merges[pair]\n",
    "        tokens = merge(tokens, pair, idx)\n",
    "    return tokens\n",
    "\n",
    "encode(\"Hello world\")"
   ],
   "id": "40ab147f486701f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[72, 101, 108, 108, 111, 32, 119, 266, 108, 100]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T14:02:06.008819Z",
     "start_time": "2025-05-17T14:02:06.005613Z"
    }
   },
   "cell_type": "code",
   "source": "decode(encode(\"Hello world\"))",
   "id": "da59bdeac4d8335a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello world'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T15:32:16.904206Z",
     "start_time": "2025-05-17T15:32:16.901313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gpt2pat = re.compile(r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\")\n",
    "print(re.findall(gpt2pat, \"Hello world      you    \"))"
   ],
   "id": "67678b8894fd41ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ' world', '     ', ' you', '    ']\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T15:31:59.307067Z",
     "start_time": "2025-05-17T15:31:59.303112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "\n",
    "gpt2_enc = tiktoken.get_encoding('gpt2')\n",
    "print(gpt2_enc.encode(\"     Hello world\"))\n",
    "\n",
    "gpt4_enc = tiktoken.get_encoding('cl100k_base')\n",
    "gpt4_enc.encode(\"     Hello world\")"
   ],
   "id": "74f546215dc4d291",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[220, 220, 220, 220, 18435, 995]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[257, 22691, 1917]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T18:16:10.585812Z",
     "start_time": "2025-05-17T18:16:02.320868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!wget https://openaipublic.blob.core.windows.net/gpt-2/models/1558M/vocab.bpe\n",
    "!wget https://openaipublic.blob.core.windows.net/gpt-2/models/1558M/encoder.json"
   ],
   "id": "5645cfe0cc605b69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-17 23:46:02--  https://openaipublic.blob.core.windows.net/gpt-2/models/1558M/vocab.bpe\r\n",
      "Resolving openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)... 57.150.97.129\r\n",
      "Connecting to openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)|57.150.97.129|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 456318 (446K) [application/octet-stream]\r\n",
      "Saving to: â€˜vocab.bpeâ€™\r\n",
      "\r\n",
      "vocab.bpe           100%[===================>] 445.62K   211KB/s    in 2.1s    \r\n",
      "\r\n",
      "2025-05-17 23:46:06 (211 KB/s) - â€˜vocab.bpeâ€™ saved [456318/456318]\r\n",
      "\r\n",
      "--2025-05-17 23:46:06--  https://openaipublic.blob.core.windows.net/gpt-2/models/1558M/encoder.json\r\n",
      "Resolving openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)... 57.150.97.129\r\n",
      "Connecting to openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)|57.150.97.129|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 1042301 (1018K) [application/json]\r\n",
      "Saving to: â€˜encoder.jsonâ€™\r\n",
      "\r\n",
      "encoder.json        100%[===================>]   1018K   350KB/s    in 2.9s    \r\n",
      "\r\n",
      "2025-05-17 23:46:10 (350 KB/s) - â€˜encoder.jsonâ€™ saved [1042301/1042301]\r\n",
      "\r\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T18:17:03.817140Z",
     "start_time": "2025-05-17T18:17:03.786764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, json\n",
    "\n",
    "with open('encoder.json', 'r') as f:\n",
    "    encoder = json.load(f) # <--- ~equivalent to our \"vocab\"\n",
    "\n",
    "with open('vocab.bpe', 'r', encoding=\"utf-8\") as f:\n",
    "    bpe_data = f.read()\n",
    "bpe_merges = [tuple(merge_str.split()) for merge_str in bpe_data.split('\\n')[1:-1]]\n",
    "# ^---- ~equivalent to our \"merges\""
   ],
   "id": "294e66b4015bfdc4",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T18:17:14.342318Z",
     "start_time": "2025-05-17T18:17:14.338905Z"
    }
   },
   "cell_type": "code",
   "source": "len(encoder)",
   "id": "532e08b18d24f5f6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T18:17:25.785432Z",
     "start_time": "2025-05-17T18:17:25.782983Z"
    }
   },
   "cell_type": "code",
   "source": "encoder['<|endoftext|>']",
   "id": "a1e04e8fd6f1b86",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T18:18:18.816550Z",
     "start_time": "2025-05-17T18:18:18.808184Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8c7960c1fee0260e",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'hellooo'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[49], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mencoder\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mhellooo\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'hellooo'"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2caa51a9f66853ae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
