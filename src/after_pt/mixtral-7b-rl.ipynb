{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-20T11:27:41.837524Z",
     "start_time": "2025-06-20T11:27:28.071357Z"
    }
   },
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from huggingface_hub import login\n",
    "\n",
    "from after_pt.reward_model import RewardModel\n",
    "\n",
    "login(token='<>')\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/subhojit/workspace/saturn/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/subhojit/workspace/saturn/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.43s/it]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:27:45.353490Z",
     "start_time": "2025-06-20T11:27:45.350692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys, os\n",
    "project_root = os.path.abspath('/Users/subhojit/workspace/saturn/src')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from after_pt import *"
   ],
   "id": "3cd6f493e95a1f7c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:27:58.365004Z",
     "start_time": "2025-06-20T11:27:46.628689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"mps\"\n",
    "model = model.to(device)"
   ],
   "id": "c695c98bac3a9262",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:28:29.518531Z",
     "start_time": "2025-06-20T11:28:29.510275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"\"\"<s>[INST] Who is Kurt Godel ? [/INST]\"\"\"\n",
    "encodeds = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)"
   ],
   "id": "1140cb9760c58d8b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:28:30.866874Z",
     "start_time": "2025-06-20T11:28:30.860907Z"
    }
   },
   "cell_type": "code",
   "source": "model_inputs = encodeds.to(device)\n",
   "id": "f765e6d35afc3d15",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:28:50.501567Z",
     "start_time": "2025-06-20T11:28:32.034296Z"
    }
   },
   "cell_type": "code",
   "source": "generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True)",
   "id": "b06fa1c2bf36fff0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:29:06.647548Z",
     "start_time": "2025-06-20T11:29:06.640537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ],
   "id": "de80244e69b9601a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Who is Kurt Godel ? [/INST] Kurt Godel (1906-1978) was a German logician and mathematician, known for his work in axiomatic set theory, proof theory, and mathematical logic. Godel is famous for his Godel's incompleteness theorems, which show that within any axiomatic system that contains basic arithmetic, there will always be true statements that cannot be proven within that system. Godel's work also introduced new definitions and methods in mathematical logic, and helped to lay the foundation for the development of modern computability theory.</s>\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:30:26.994706Z",
     "start_time": "2025-06-20T11:30:26.990241Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e0eace7dad1c0db1",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T14:03:27.332915Z",
     "start_time": "2025-06-20T14:03:15.244241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class RewardModelLite1(nn.Module):\n",
    "    def __init__(self, base_model, tokenizer):\n",
    "        super().__init__()\n",
    "        device = \"mps\"\n",
    "        self.base_model = base_model.to(device)\n",
    "        self.tokenizer = tokenizer\n",
    "        # scalar reward head\n",
    "        self.reward_head = nn.Linear(self.base_model.config.hidden_size, 1, device=device)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        outputs = self.base_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True\n",
    "        )\n",
    "        last_hidden_state = outputs.hidden_states[-1]\n",
    "        last_token_idx = attention_mask.sum(dim=1) - 1  # (B,)\n",
    "        last_token_hidden = last_hidden_state[torch.arange(last_hidden_state.size(0)), last_token_idx]  # (B, D)\n",
    "        reward = self.reward_head(last_token_hidden).squeeze(-1)  # (B,)\n",
    "        return reward\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "text = \"<s>[INST] What is dropout in neural networks? [/INST] Dropout is a regularization technique to switch off neuron randomly\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "reward_model = RewardModelLite1(model, tokenizer)\n",
    "reward = reward_model(**inputs)  # scalar for each example\n",
    "print(reward)\n"
   ],
   "id": "929e28cd5c09ed6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.8087], device='mps:0', grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "703d79e4deee90e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
